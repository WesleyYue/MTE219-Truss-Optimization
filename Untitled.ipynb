{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import math\n",
    "import numpy as np\n",
    "rng = np.random\n",
    "\n",
    "session = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "# dowel\n",
    "dowel_diameter = tf.constant(3.17e-3)  # 1/8 inch = 3.17 mm\n",
    "dowel_shear_strength = tf.constant(23e6)\n",
    "dowel_ultimate_strength = tf.constant(117e6)\n",
    "\n",
    "height = tf.constant(50e-3, dtype=tf.float64)  # m\n",
    "length = tf.constant(300e-3, dtype=tf.float64)  # m\n",
    "\n",
    "\n",
    "# balsa wood constants\n",
    "elastic_modulus = tf.constant(2.617e9)\n",
    "ultimate_strength_tensile = tf.constant(12.727e6)\n",
    "shear_strength_balsa = tf.constant(2e6)\n",
    "balsa_density = tf.constant(105.)  #kg/m^3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def merge_tensor_arrays(t1, t2):\n",
    "    tf.assert_equal(tf.shape(t1), tf.shape(t2))\n",
    "    tf.assert_rank(t1, 1)\n",
    "    tf.assert_rank(t2, 1)\n",
    "\n",
    "    \n",
    "    r = tf.concat(0, [t1, t2])\n",
    "    r = tf.reshape(r, [2, tf.size(t1)])\n",
    "    return r\n",
    "    \n",
    "    \n",
    "# x = tf.Variable([1, 2, 3, 4])\n",
    "# y = tf.Variable([1, 2, 3, 3])\n",
    "# # print(tf.shape(x).eval())\n",
    "# # print(tf.shape(y).eval())\n",
    "# tf.initialize_all_variables().run()\n",
    "# print(merge_tensor_arrays(x, y).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horizontal, vertical\n",
      "width_comp:\n",
      "[[ 0.00046665  0.0012373 ]\n",
      " [ 0.00511081  0.00687154]]\n",
      "thickness_comp: \n",
      "[[ 0.0015341   0.00209088]\n",
      " [ 0.00339119  0.0094042 ]]\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "# sections_constant = tf.constant(4, dtype=tf.int32)\n",
    "sections_constant = 2\n",
    "\n",
    "comp_sections = tf.constant(sections_constant, dtype=tf.int32, name=\"comp_sections\")\n",
    "tensile_sections = tf.constant(sections_constant - 1, dtype=tf.int32, name=\"tensile_sections\")\n",
    "\n",
    "# compressive: [horizontal, vertical]\n",
    "width_comp = tf.Variable(tf.random_uniform([2, sections_constant]), dtype=tf.float32, name=\"width_comp\") / 100\n",
    "thickness_comp = tf.Variable(tf.random_uniform([2, sections_constant]), dtype=tf.float32, name=\"thickness_comp\") / 100\n",
    "# length_comp = tf.Variable(tf.fill([2, sections_constant], rng.ranf()), dtype=tf.float32, name=\"length_comp\") / 100  # pin to pin length \n",
    "\n",
    "tf.initialize_all_variables().run()\n",
    "print(\"horizontal, vertical\")\n",
    "print(\"width_comp:\")\n",
    "print(width_comp.eval())\n",
    "print(\"thickness_comp: \")\n",
    "print(thickness_comp.eval())\n",
    "# print(\"length_comp: \")\n",
    "# print(length_comp.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horizontal, diagonal\n",
      "width_tensile: \n",
      "[[ 0.          0.57138813]\n",
      " [ 0.44808769  0.71285176]]\n",
      "thickness_tensile: \n",
      "[[ 0.          0.91477025]\n",
      " [ 0.45349312  0.89675534]]\n",
      "tearout_d_tensile: \n",
      "[[ 0.          0.95213342]\n",
      " [ 0.27066445  0.76026845]]\n",
      "load: \n",
      "6.0\n"
     ]
    }
   ],
   "source": [
    "def generate_tensile_horizontal(clip = 1e-9):\n",
    "    r = tf.random_uniform([sections_constant - 1])\n",
    "    r = tf.Variable(r)\n",
    "    r = tf.clip_by_value(r, clip, float(\"inf\"))\n",
    "    r = tf.concat(0, [[0.], r])\n",
    "    return r\n",
    "\n",
    "def generate_tensile_diagonal(clip = 0):\n",
    "    r = tf.random_uniform([sections_constant])\n",
    "    r = tf.Variable(r)\n",
    "    r = tf.clip_by_value(r, clip + 1e-9, float(\"inf\"))\n",
    "#     r = tf.concat(0, [[0.], r])\n",
    "    return r\n",
    "\n",
    "# There is always one less horizontal than diagonal for tensile\n",
    "width_tensile_horizontal = generate_tensile_horizontal(dowel_diameter + 1e-5)\n",
    "thickness_tensile_horizontal = generate_tensile_horizontal(dowel_diameter)\n",
    "tearout_d_tensile_horizontal = generate_tensile_horizontal()\n",
    "\n",
    "width_tensile_diagonal = generate_tensile_diagonal(dowel_diameter + 1e-5)\n",
    "thickness_tensile_diagonal = generate_tensile_diagonal(dowel_diameter)\n",
    "tearout_d_tensile_diagonal = generate_tensile_diagonal()\n",
    "\n",
    "\n",
    "# tensile: [horizontal,  diagonal]\n",
    "\n",
    "# width_tensile = tf.Variable(tf.zeros([2, sections_constant]), dtype=tf.float32, trainable=False)\n",
    "# thickness_tensile = tf.Variable(tf.zeros([2, sections_constant]), dtype=tf.float32, trainable=False)\n",
    "# tearout_d_tensile = tf.Variable(tf.zeros([2, sections_constant]), dtype=tf.float32, trainable=False)\n",
    "\n",
    "# width_tensile = tf.scatter_update(width_tensile, [0, 1], [width_tensile_horizontal, width_tensile_diagonal]) \n",
    "# thickness_tensile = tf.scatter_update(width_tensile, [0, 1], [thickness_tensile_horizontal, thickness_tensile_diagonal])\n",
    "# tearout_d_tensile = tf.scatter_update(width_tensile, [0, 1], [tearout_d_tensile_horizontal, tearout_d_tensile_diagonal])\n",
    "\n",
    "width_tensile = merge_tensor_arrays(width_tensile_horizontal, width_tensile_diagonal)\n",
    "thickness_tensile = merge_tensor_arrays(thickness_tensile_horizontal, thickness_tensile_diagonal)\n",
    "tearout_d_tensile = merge_tensor_arrays(tearout_d_tensile_horizontal, tearout_d_tensile_diagonal)\n",
    "\n",
    "\n",
    "# load_int = tf.Variable(4, dtype=tf.int32)  # Force in newtons\n",
    "# LOAD_STEP = tf.constant(0.5)  # load step is 500g\n",
    "# load = tf.to_float(load_int) * LOAD_STEP\n",
    "load = tf.Variable(6., name=\"load\")\n",
    "load = tf.maximum(load, 0.5*9.81)\n",
    "# load = tf.clip_by_value(load, 0.5*9.81, float(\"inf\"))\n",
    "\n",
    "tf.initialize_all_variables().run()\n",
    "print(\"horizontal, diagonal\")\n",
    "print(\"width_tensile: \")\n",
    "print(width_tensile.eval())\n",
    "print(\"thickness_tensile: \")\n",
    "print(thickness_tensile.eval())\n",
    "print(\"tearout_d_tensile: \")\n",
    "print(tearout_d_tensile.eval())\n",
    "print(\"load: \")\n",
    "print(load.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta = tf.atan(height / (length / tf.to_double(comp_sections)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length_comp\n",
      "[[ 0.15000001  0.15000001]\n",
      " [ 0.05        0.05      ]]\n",
      "length_tensile\n",
      "[[ 0.          0.15      ]\n",
      " [ 0.15811388  0.15811388]]\n"
     ]
    }
   ],
   "source": [
    "# compressive member lengths\n",
    "length_vertical_comp = tf.fill([sections_constant], height)\n",
    "length_horizontal_comp = tf.fill([sections_constant], length/sections_constant)\n",
    "\n",
    "length_comp = tf.Variable(tf.zeros([2, sections_constant]), trainable=False)\n",
    "length_comp = tf.scatter_update(length_comp, [0, 1], [tf.to_float(length_horizontal_comp), tf.to_float(length_vertical_comp)])\n",
    "\n",
    "# tensile member lengths\n",
    "length_diagonal_tensile = tf.fill([sections_constant], height/tf.sin(theta))\n",
    "length_horizontal_tensile = tf.concat(0, [[0], tf.fill([sections_constant - 1], length/sections_constant)])\n",
    "\n",
    "# length_tensile = tf.Variable(tf.zeros([2, sections_constant]), trainable=False)\n",
    "# length_tensile = tf.scatter_update(length_comp, [0, 1], [tf.to_float(length_horizontal_tensile), tf.to_float(length_diagonal_tensile)])\n",
    "length_tensile = merge_tensor_arrays(length_horizontal_tensile, length_diagonal_tensile)\n",
    "\n",
    "tf.initialize_all_variables().run()\n",
    "print(\"length_comp\")\n",
    "print(length_comp.eval())\n",
    "print(\"length_tensile\")\n",
    "print(length_tensile.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horizontal, vertical\n",
      "width_comp:\n",
      "[[ 0.00317     0.00600168]\n",
      " [ 0.00317     0.00317   ]]\n",
      "thickness_comp: \n",
      "[[ 0.00375718  0.00317   ]\n",
      " [ 0.00317     0.00673582]]\n",
      "length_comp: \n",
      "[[ 0.15000001  0.15000001]\n",
      " [ 0.05        0.05      ]]\n",
      "\n",
      "horizontal, diagonal\n",
      "width_tensile: \n",
      "[[ 0.          0.16493332]\n",
      " [ 0.82842076  0.10446286]]\n",
      "thickness_tensile: \n",
      "[[ 0.          0.4008646 ]\n",
      " [ 0.19287539  0.09410608]]\n",
      "tearout_d_tensile: \n",
      "[[ 0.          0.46128798]\n",
      " [ 0.36885703  0.86368382]]\n"
     ]
    }
   ],
   "source": [
    "# width_tensile = tf.clip_by_value(width_tensile, dowel_diameter + 1e-9, float(\"inf\"))\n",
    "width_comp = tf.clip_by_value(width_comp, dowel_diameter + 1e-9, float(\"inf\"))\n",
    "\n",
    "thickness_comp = tf.clip_by_value(thickness_comp, dowel_diameter + 1e-9, float(\"inf\"))\n",
    "# thickness_tensile = tf.clip_by_value(thickness_tensile, dowel_diameter + 1e-9, float(\"inf\"))\n",
    "\n",
    "\n",
    "\n",
    "print(\"horizontal, vertical\")\n",
    "print(\"width_comp:\")\n",
    "print(width_comp.eval())\n",
    "print(\"thickness_comp: \")\n",
    "print(thickness_comp.eval())\n",
    "print(\"length_comp: \")\n",
    "print(length_comp.eval())\n",
    "\n",
    "print()\n",
    "print(\"horizontal, diagonal\")\n",
    "print(\"width_tensile: \")\n",
    "print(width_tensile.eval())\n",
    "print(\"thickness_tensile: \")\n",
    "print(thickness_tensile.eval())\n",
    "print(\"tearout_d_tensile: \")\n",
    "print(tearout_d_tensile.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp_sections:\n",
      "2\n",
      "comp_vertical:\n",
      "[ 6.  0.]\n",
      "comp_horizontal:\n",
      "[ 18.  36.]\n",
      "comp_forces:\n",
      "[[ 18.  36.]\n",
      " [  6.   0.]]\n",
      "tensile_horizontal:\n",
      "[  0.  18.]\n",
      "tensile_diag:\n",
      "[ 18.97366596  18.97366596]\n",
      "tensile_forces:\n",
      "[[  0.          18.        ]\n",
      " [ 18.97366596  18.97366596]]\n"
     ]
    }
   ],
   "source": [
    "# ForcesPart\n",
    "\n",
    "sections_range = tf.to_double(tf.range(1, 100))[:comp_sections]\n",
    "# sections_range = np.arange(1, sections_constant+1)\n",
    "# sections_range\n",
    "\n",
    "\n",
    "# Forces\n",
    "# Last vertical member has 0 force\n",
    "comp_vertical = tf.fill([sections_constant - 1], tf.to_double(load))\n",
    "# comp_vertical = tf.maximum(comp_vertical, 0.5*9.81)\n",
    "comp_vertical = tf.concat(0, [comp_vertical, [0]])\n",
    "# comp_vertical = tf.concat(0, [[load] *(comp_sections - 1), [0]])\n",
    "\n",
    "comp_lowest_horizontal = tf.to_double(load) / tf.tan(theta)\n",
    "comp_horizontal = comp_lowest_horizontal * sections_range\n",
    "# comp_horizontal = tf.maximum(comp_horizontal, 0.5*9.81)\n",
    "\n",
    "comp_forces = tf.concat(0, [comp_horizontal, comp_vertical])\n",
    "comp_forces = tf.reshape(comp_forces, [2,sections_constant])\n",
    "# comp_forces = tf.maximum(comp_forces, 0.5*9.81)\n",
    "# comp_forces = tf.clip_by_value(comp_forces, 0.5*9.81, float(\"inf\"))\n",
    "\n",
    "\n",
    "\n",
    "# TODO: fix the clipping here to be tensile_dimensions\n",
    "tensile_lowest_horizontal = comp_lowest_horizontal\n",
    "\n",
    "tensile_horizontal = tensile_lowest_horizontal * sections_range[:-1]\n",
    "# tensile_horizontal = tf.maximum(tensile_horizontal, 0.5*9.81)\n",
    "tensile_horizontal = tf.concat(0, [[0], tensile_horizontal])\n",
    "tensile_diag = tf.fill([sections_constant], tf.to_double(load) / tf.sin(theta))\n",
    "\n",
    "tensile_forces = tf.concat(0, [tensile_horizontal, tensile_diag])\n",
    "tensile_forces = tf.reshape(tensile_forces, [2,sections_constant])\n",
    "\n",
    "# tensile_horizontal = generate_tensile_horizontal(0.5*9.81)\n",
    "# tensile_diag = generate_tensile_diagonal(0.5*9.81)\n",
    "\n",
    "\n",
    "# load = tf.clip_by_value(load, 0.5*9.81, float(\"inf\"))\n",
    "\n",
    "# tf.initialize_all_variables().run()\n",
    "print(\"comp_sections:\")\n",
    "print(comp_sections.eval())\n",
    "print(\"comp_vertical:\")\n",
    "print(comp_vertical.eval())\n",
    "print(\"comp_horizontal:\")\n",
    "print(comp_horizontal.eval())\n",
    "print(\"comp_forces:\")\n",
    "print(comp_forces.eval())\n",
    "print(\"tensile_horizontal:\")\n",
    "print(tensile_horizontal.eval())\n",
    "print(\"tensile_diag:\")\n",
    "print(tensile_diag.eval())\n",
    "print(\"tensile_forces:\")\n",
    "print(tensile_forces.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucking: \n",
      "[[  11.44933033   18.28902054]\n",
      " [  86.94000244  184.73565674]]\n",
      "pin_shear: \n",
      "181.525\n",
      "plate_rupture: \n",
      "[[      -0.      825284.75 ]\n",
      " [ 2025763.625   121317.25 ]]\n",
      "bearing_failure: \n",
      "[[ 1393.50134277  1175.72155762]\n",
      " [ 1175.72155762  2498.24804688]]\n",
      "plate_tearout: \n",
      "[[      0.       739656.0625 ]\n",
      " [ 284573.75     325111.59375]]\n"
     ]
    }
   ],
   "source": [
    "# Helper Variables\n",
    "\n",
    "Ixx = 1/12 * thickness_comp * width_comp**3\n",
    "Iyy = 1/12 * width_comp * thickness_comp**3\n",
    "I_min = tf.minimum(Ixx, Iyy)  # Compressive\n",
    "\n",
    "# Failure Modes (Force at which they fail)\n",
    "buckling = (math.pi**2 * elastic_modulus * I_min / length_comp**2)  # compressive\n",
    "pin_shear = (dowel_diameter**2 * math.pi * dowel_shear_strength / 4)  # tensile and compressive\n",
    "plate_rupture = (width_tensile - dowel_diameter) * thickness_tensile * ultimate_strength_tensile  # tensile\n",
    "bearing_failure = thickness_comp * dowel_diameter * dowel_ultimate_strength  # compressive\n",
    "plate_tearout = tearout_d_tensile * 2 * thickness_tensile * shear_strength_balsa  # tensile\n",
    "\n",
    "print(\"bucking: \")\n",
    "print(buckling.eval())\n",
    "print(\"pin_shear: \")\n",
    "print(pin_shear.eval())\n",
    "print(\"plate_rupture: \")\n",
    "print(plate_rupture.eval())\n",
    "print(\"bearing_failure: \")\n",
    "print(bearing_failure.eval())\n",
    "print(\"plate_tearout: \")\n",
    "print(plate_tearout.eval())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00317     0.00600168]\n",
      " [ 0.00317     0.00317   ]]\n",
      "[[ 0.00375718  0.00317   ]\n",
      " [ 0.00317     0.00673582]]\n",
      "[[ 0.15000001  0.15000001]\n",
      " [ 0.05        0.05      ]]\n",
      "[[  1.87586775e-04   2.99648847e-04]\n",
      " [  5.27567536e-05   1.12100905e-04]]\n",
      "--\n",
      "[[ 0.          0.15      ]\n",
      " [ 0.15811388  0.15811388]]\n",
      "[[ 0.          1.04132593]\n",
      " [ 2.65269375  0.16320704]]\n"
     ]
    }
   ],
   "source": [
    "# Mass calculations\n",
    "comp_mass = width_comp * thickness_comp * length_comp * balsa_density\n",
    "tensile_mass = width_tensile * thickness_tensile * tf.to_float(length_tensile) * balsa_density\n",
    "\n",
    "print(width_comp.eval())\n",
    "print(thickness_comp.eval())\n",
    "print(length_comp.eval())\n",
    "print(comp_mass.eval())\n",
    "\n",
    "print(\"--\")\n",
    "print(length_tensile.eval())\n",
    "print(tensile_mass.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "bearing_failure: [[ 2743.57519531  1175.72155762]\n",
      " [ 2989.81933594  1175.72155762]]\n",
      "load: 6.050000190734863\n",
      "comp_forces: [[ 18.15000057  36.30000114]\n",
      " [  6.05000019   0.        ]]\n",
      "langranian: 0.0\n",
      "bearing_failure_cost: 64389994.63417598\n",
      "length_comp: [[ 0.15000001  0.15000001]\n",
      " [ 0.05        0.05      ]]\n",
      "width_comp: [[ 0.00317     0.00757946]\n",
      " [ 0.00317     0.00419567]]\n",
      "thickness_comp: [[ 0.00739727  0.00317   ]\n",
      " [ 0.0080612   0.00317   ]]\n",
      "-----\n",
      "bearing_failure: [[ 1175.72155762  1175.72155762]\n",
      " [ 1175.72155762  1175.72155762]]\n",
      "load: 100.63500213623047\n",
      "comp_forces: [[ 301.90500641  603.81001282]\n",
      " [ 100.63500214    0.        ]]\n",
      "langranian: 0.0\n",
      "bearing_failure_cost: 13664379.94523505\n",
      "length_comp: [[ 0.15000001  0.15000001]\n",
      " [ 0.05        0.05      ]]\n",
      "width_comp: [[ 0.00317  0.00317]\n",
      " [ 0.00317  0.00317]]\n",
      "thickness_comp: [[ 0.00317  0.00317]\n",
      " [ 0.00317  0.00317]]\n",
      "-----\n",
      "bearing_failure: [[ 1175.72155762  1175.72155762]\n",
      " [ 1175.72155762  1175.72155762]]\n",
      "load: 189.81280517578125\n",
      "comp_forces: [[  569.43841553  1138.87683105]\n",
      " [  189.81280518     0.        ]]\n",
      "langranian: 0.0\n",
      "bearing_failure_cost: 7866668.441045895\n",
      "length_comp: [[ 0.15000001  0.15000001]\n",
      " [ 0.05        0.05      ]]\n",
      "width_comp: [[ 0.00317  0.00317]\n",
      " [ 0.00317  0.00317]]\n",
      "thickness_comp: [[ 0.00317  0.00317]\n",
      " [ 0.00317  0.00317]]\n",
      "-----\n",
      "bearing_failure: [[ 1175.72155762  1175.72155762]\n",
      " [ 1175.72155762  1175.72155762]]\n",
      "load: 196.2080535888672\n",
      "comp_forces: [[  588.62416077  1177.24832153]\n",
      " [  196.20805359     0.        ]]\n",
      "langranian: 871.6661769509635\n",
      "bearing_failure_cost: 7512015.8554425845\n",
      "length_comp: [[ 0.15000001  0.15000001]\n",
      " [ 0.05        0.05      ]]\n",
      "width_comp: [[ 0.00317  0.00317]\n",
      " [ 0.00317  0.00317]]\n",
      "thickness_comp: [[ 0.00317  0.00317]\n",
      " [ 0.00317  0.00317]]\n",
      "-----\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-8139d66ce288>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;31m#     tf.get_default_session().run(train2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#     tf.get_default_session().run(train3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/var/pyenv/versions/3.5.2/envs/219optimizer/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 717\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    718\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/var/pyenv/versions/3.5.2/envs/219optimizer/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 915\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    916\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/var/pyenv/versions/3.5.2/envs/219optimizer/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 965\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/var/pyenv/versions/3.5.2/envs/219optimizer/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    970\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/var/pyenv/versions/3.5.2/envs/219optimizer/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    952\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    953\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TrainingPart\n",
    "# Bearing Failure (Compressive)\n",
    "\n",
    "# difference between critical force and experienced force\n",
    "bearing_critical_experience_diff = tf.to_double(bearing_failure) - comp_forces\n",
    "bearing_failure_cost = ((tf.reduce_sum(bearing_critical_experience_diff)**2))\n",
    "langranian = tf.minimum(tf.reduce_min(bearing_critical_experience_diff), 0)**16\n",
    "\n",
    "opt = tf.train.AdamOptimizer(0.05)\n",
    "train = opt.minimize(bearing_failure_cost + langranian + tf.to_double(comp_mass/load))\n",
    "# train3 = opt.minimize()\n",
    "# train = opt.minimize(load)\n",
    "\n",
    "training_epoch = 10000\n",
    "display_step = 2000\n",
    "\n",
    "tf.initialize_all_variables().run()\n",
    "print(\"training...\")\n",
    "for epoch in range(training_epoch):\n",
    "    tf.get_default_session().run(train)\n",
    "#     tf.get_default_session().run(train2)\n",
    "#     tf.get_default_session().run(train3)\n",
    "\n",
    "    \n",
    "    if (epoch) % display_step == 0:\n",
    "#         print((buckling - comp_forces).eval())\n",
    "        print(\"bearing_failure: {0}\".format(bearing_failure.eval()))\n",
    "        print(\"load: {0}\".format(load.eval()))\n",
    "        print(\"comp_forces: {0}\".format(comp_forces.eval()))\n",
    "        print(\"langranian: {0}\".format(langranian.eval()))\n",
    "\n",
    "        print(\"bearing_failure_cost: {0}\".format(bearing_failure_cost.eval()))\n",
    "        print(\"length_comp: {0}\".format(length_comp.eval()))\n",
    "        print(\"width_comp: {0}\".format(width_comp.eval()))\n",
    "        print(\"thickness_comp: {0}\".format(thickness_comp.eval()))\n",
    "\n",
    "        print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "buckling: \n",
      "[[  27.941782     48.5682373 ]\n",
      " [ 131.22982788  210.94206238]]\n",
      "comp_forces: \n",
      "[[ 17.84999943  35.69999886]\n",
      " [  5.94999981   0.        ]]\n",
      "comp_mass: \n",
      "[[  4.57800517e-04   3.66762135e-04]\n",
      " [  7.96326058e-05   1.28003419e-04]]\n",
      "length_comp: \n",
      "[[ 0.15000001  0.15000001]\n",
      " [ 0.05        0.05      ]]\n",
      "width_comp: \n",
      "[[ 0.0091693   0.00498712]\n",
      " [ 0.00317     0.00317   ]]\n",
      "thickness_comp: \n",
      "[[ 0.00317     0.00466933]\n",
      " [ 0.00478489  0.00769136]]\n",
      "langranian: 0.0\n",
      "buckling_failure_cost: 129011.64552616958\n",
      "load: 5.949999809265137\n",
      "-----\n",
      "buckling: \n",
      "[[  22.49048424  264.33074951]\n",
      " [  86.94000244   86.94000244]]\n",
      "comp_forces: \n",
      "[[ 17.09917974  34.19835949]\n",
      " [  5.69972658   0.        ]]\n",
      "comp_mass: \n",
      "[[  3.68486013e-04   8.46056035e-04]\n",
      " [  5.27567536e-05   5.27567536e-05]]\n",
      "length_comp: \n",
      "[[ 0.15000001  0.15000001]\n",
      " [ 0.05        0.05      ]]\n",
      "width_comp: \n",
      "[[ 0.00738042  0.00748986]\n",
      " [ 0.00317     0.00317   ]]\n",
      "thickness_comp: \n",
      "[[ 0.00317     0.00717207]\n",
      " [ 0.00317     0.00317   ]]\n",
      "langranian: 0.0\n",
      "buckling_failure_cost: 162976.89766779897\n",
      "load: 5.699726581573486\n",
      "-----\n",
      "buckling: \n",
      "[[  18.6732254   264.33074951]\n",
      " [  86.94000244   86.94000244]]\n",
      "comp_forces: \n",
      "[[ 17.09917974  34.19835949]\n",
      " [  5.69972658   0.        ]]\n",
      "comp_mass: \n",
      "[[  3.05943686e-04   8.46056035e-04]\n",
      " [  5.27567536e-05   5.27567536e-05]]\n",
      "length_comp: \n",
      "[[ 0.15000001  0.15000001]\n",
      " [ 0.05        0.05      ]]\n",
      "width_comp: \n",
      "[[ 0.00612776  0.00748986]\n",
      " [ 0.00317     0.00317   ]]\n",
      "thickness_comp: \n",
      "[[ 0.00317     0.00717207]\n",
      " [ 0.00317     0.00317   ]]\n",
      "langranian: 0.0\n",
      "buckling_failure_cost: 159909.3840190247\n",
      "load: 5.699726581573486\n",
      "-----\n",
      "buckling: \n",
      "[[  16.34132576  264.33074951]\n",
      " [  86.94000244   86.94000244]]\n",
      "comp_forces: \n",
      "[[ 17.09917974  34.19835949]\n",
      " [  5.69972658   0.        ]]\n",
      "comp_mass: \n",
      "[[  2.67737632e-04   8.46056035e-04]\n",
      " [  5.27567536e-05   5.27567536e-05]]\n",
      "length_comp: \n",
      "[[ 0.15000001  0.15000001]\n",
      " [ 0.05        0.05      ]]\n",
      "width_comp: \n",
      "[[ 0.00536253  0.00748986]\n",
      " [ 0.00317     0.00317   ]]\n",
      "thickness_comp: \n",
      "[[ 0.00317     0.00717207]\n",
      " [ 0.00317     0.00317   ]]\n",
      "langranian: 0.011840461115963674\n",
      "buckling_failure_cost: 158049.83040386558\n",
      "load: 5.699726581573486\n",
      "-----\n",
      "buckling: \n",
      "[[  16.34132195  264.33074951]\n",
      " [  86.94000244   86.94000244]]\n",
      "comp_forces: \n",
      "[[ 17.09917974  34.19835949]\n",
      " [  5.69972658   0.        ]]\n",
      "comp_mass: \n",
      "[[  2.67737632e-04   8.46056035e-04]\n",
      " [  5.27567536e-05   5.27567536e-05]]\n",
      "length_comp: \n",
      "[[ 0.15000001  0.15000001]\n",
      " [ 0.05        0.05      ]]\n",
      "width_comp: \n",
      "[[ 0.00536253  0.00748986]\n",
      " [ 0.00317     0.00317   ]]\n",
      "thickness_comp: \n",
      "[[ 0.00317     0.00717207]\n",
      " [ 0.00317     0.00317   ]]\n",
      "langranian: 0.011841414745148068\n",
      "buckling_failure_cost: 158049.82737076306\n",
      "load: 5.699726581573486\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# TrainingPart\n",
    "# Buckling (Compressive)\n",
    "\n",
    "# difference between critical force and experienced force\n",
    "buckling_critical_experience_diff = tf.to_double(buckling) - comp_forces\n",
    "buckling_failure_cost = ((tf.reduce_sum(buckling_critical_experience_diff)**2))\n",
    "langranian = tf.minimum(tf.reduce_min(buckling_critical_experience_diff), 0)**16\n",
    "\n",
    "opt = tf.train.AdamOptimizer(0.05)\n",
    "train = opt.minimize(buckling_critical_experience_diff + langranian + tf.to_double(comp_mass/load))\n",
    "# train3 = opt.minimize()\n",
    "# train2 = opt.minimize(load)\n",
    "\n",
    "training_epoch = 10000\n",
    "display_step = 2000\n",
    "\n",
    "tf.initialize_all_variables().run()\n",
    "print(\"training...\")\n",
    "for epoch in range(training_epoch):\n",
    "    tf.get_default_session().run(train)\n",
    "#     tf.get_default_session().run(train2)\n",
    "#     tf.get_default_session().run(train3)\n",
    "\n",
    "    \n",
    "    if (epoch) % display_step == 0:\n",
    "#         print((buckling - comp_forces).eval())\n",
    "        print(\"buckling: \\n{0}\".format(buckling.eval()))\n",
    "        print(\"comp_forces: \\n{0}\".format(comp_forces.eval()))\n",
    "        print(\"comp_mass: \\n{0}\".format(comp_mass.eval()))\n",
    "\n",
    "        print(\"length_comp: \\n{0}\".format(length_comp.eval()))\n",
    "        print(\"width_comp: \\n{0}\".format(width_comp.eval()))\n",
    "        print(\"thickness_comp: \\n{0}\".format(thickness_comp.eval()))\n",
    "        \n",
    "        print(\"langranian: {0}\".format(langranian.eval()))\n",
    "        print(\"buckling_failure_cost: {0}\".format(buckling_failure_cost.eval()))\n",
    "        print(\"load: {0}\".format(load.eval()))\n",
    "\n",
    "        print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TrainingPart\n",
    "# Plate Rupture (Tensile)\n",
    "# plate_rupture = tf.fill([2, 4])\n",
    "print(plate_rupture.eval())\n",
    "\n",
    "# sigma = 1e-5\n",
    "sigma = 1*10**-7.5\n",
    "# difference between critical force and experienced force\n",
    "plate_rupture_critical_experienced_diff = tf.to_double(plate_rupture) - tensile_forces\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plate_rupture_failure_cost = (((plate_rupture_critical_experienced_diff)**2))\n",
    "# plate_rupture_failure_cost = tf.reduce_max((tf.reduce_max(plate_rupture_critical_experienced_diff)**2))\n",
    "\n",
    "langranian = tf.minimum(tf.reduce_min(plate_rupture_critical_experienced_diff), 0)**2/(2*sigma)\n",
    "tensile_mass_to_load = tf.reduce_sum(tensile_mass/load) \n",
    "# print(tensile_mass_to_load)\n",
    "opt = tf.train.AdamOptimizer(0.0001)\n",
    "train = opt.minimize(\n",
    "    tf.to_float(plate_rupture_failure_cost) + \n",
    "    tf.to_float(langranian) +\n",
    "    tensile_mass/load\n",
    ")\n",
    "\n",
    "training_epoch = 10000000\n",
    "display_step = 2000\n",
    "\n",
    "tf.initialize_all_variables().run()\n",
    "print(\"training...\")\n",
    "for epoch in range(training_epoch):\n",
    "    tf.get_default_session().run(train)\n",
    "#     print(epoch)\n",
    "    if (epoch) % display_step == 0:\n",
    "#         print((buckling - comp_forces).eval())\n",
    "        print(\"plate_rupture: \\n{0}\".format(plate_rupture.eval()))\n",
    "        print(\"plate_rupture_critical_experienced_diff: \\n{0}\".format(plate_rupture_critical_experienced_diff.eval()))\n",
    "\n",
    "        print(\"tensile_forces: \\n{0}\".format(tensile_forces.eval()))\n",
    "        \n",
    "#         print(\"tensile_mass: \\n{0}\".format(tensile_mass.eval()))\n",
    "        print(\"width_tensile: \\n{0}\".format(width_tensile.eval()))\n",
    "        print(\"thickness_tensile: \\n{0}\".format(thickness_tensile.eval()))\n",
    "#         print(\"length_tensile: \\n{0}\".format(length_tensile.eval()))\n",
    "#         print(\"balsa_density: {0}\".format(balsa_density.eval()))\n",
    "        \n",
    "        print(\"dowel_diameter: {0}\".format(dowel_diameter.eval()))\n",
    "        print(\"ultimate_strength_tensile: {0}\".format(ultimate_strength_tensile.eval()))\n",
    "        \n",
    "#         print(\"langarian_before: {0}\".format(tf.minimum(tf.reduce_min(plate_rupture_critical_experienced_diff), 0).eval()))\n",
    "    \n",
    "        print(\"load: {0}\".format(load.eval()))\n",
    "        print(\"plate_rupture_failure_cost: {0:.2E}\".format(tf.reduce_sum(plate_rupture_failure_cost).eval()))\n",
    "        print(\"langranian: {0:.2E}\".format(langranian.eval()))\n",
    "        print(\"tensile_mass/load: {0}\".format(tf.reduce_sum(tensile_mass/load).eval()))\n",
    "\n",
    "\n",
    "        print(\"-----\")\n",
    "        if tf.less(tf.reduce_sum(plate_rupture_failure_cost)+langranian, 0.1).eval():\n",
    "            print(\"done\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TrainingPart\n",
    "# Plate Tearout (Tensile)\n",
    "\n",
    "print(plate_tearout.eval())\n",
    "\n",
    "# sigma = 1e-5\n",
    "sigma = 1*10**-7.5\n",
    "# difference between critical force and experienced force\n",
    "plate_tear_critical_experienced_diff = tf.to_double(plate_tearout) - tensile_forces\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plate_tear_cost = (((plate_tear_critical_experienced_diff)**2))\n",
    "# plate_rupture_failure_cost = tf.reduce_max((tf.reduce_max(plate_rupture_critical_experienced_diff)**2))\n",
    "\n",
    "langranian = tf.minimum(tf.reduce_min(plate_tear_critical_experienced_diff), 0)**2/(2*sigma)\n",
    "tensile_mass_to_load = tf.reduce_sum(tensile_mass/load) \n",
    "# print(tensile_mass_to_load)\n",
    "opt = tf.train.AdamOptimizer(0.0001)\n",
    "train = opt.minimize(\n",
    "    tf.to_float(plate_tear_cost) + \n",
    "    tf.to_float(langranian) +\n",
    "    tensile_mass/load\n",
    ")\n",
    "\n",
    "# train2 = opt.minimize(    tensile_mass + \n",
    "#     -load)\n",
    "# train = opt.minimize(tensile_mass)\n",
    "\n",
    "training_epoch = 10000000\n",
    "display_step = 2000\n",
    "\n",
    "tf.initialize_all_variables().run()\n",
    "print(\"training...\")\n",
    "for epoch in range(training_epoch):\n",
    "    tf.get_default_session().run(train)\n",
    "#     tf.get_default_session().run(train2)\n",
    "\n",
    "\n",
    "    \n",
    "    if (epoch) % display_step == 0:\n",
    "#         print((buckling - comp_forces).eval())\n",
    "        print(\"plate_tearout: \\n{0}\".format(plate_tearout.eval()))\n",
    "        print(\"plate_tear_critical_experienced_diff: \\n{0}\".format(plate_tear_critical_experienced_diff.eval()))\n",
    "\n",
    "        print(\"tensile_forces: \\n{0}\".format(tensile_forces.eval()))\n",
    "        \n",
    "#         print(\"tensile_mass: \\n{0}\".format(tensile_mass.eval()))\n",
    "        print(\"tearout_d_tensile: \\n{0}\".format(tearout_d_tensile.eval()))\n",
    "        print(\"thickness_tensile: \\n{0}\".format(thickness_tensile.eval()))\n",
    "#         print(\"length_tensile: \\n{0}\".format(length_tensile.eval()))\n",
    "#         print(\"balsa_density: {0}\".format(balsa_density.eval()))\n",
    "        \n",
    "        print(\"dowel_diameter: {0}\".format(dowel_diameter.eval()))\n",
    "        print(\"ultimate_strength_tensile: {0}\".format(ultimate_strength_tensile.eval()))\n",
    "        \n",
    "#         print(\"langarian_before: {0}\".format(tf.minimum(tf.reduce_min(plate_rupture_critical_experienced_diff), 0).eval()))\n",
    "    \n",
    "        print(\"load: {0}\".format(load.eval()))\n",
    "        print(\"plate_rupture_failure_cost: {0:.2E}\".format(tf.reduce_sum(plate_tear_critical_experienced_diff).eval()))\n",
    "        print(\"langranian: {0:.2E}\".format(langranian.eval()))\n",
    "        print(\"tensile_mass/load: {0}\".format(tf.reduce_sum(tensile_mass/load).eval()))\n",
    "\n",
    "\n",
    "        print(\"-----\")\n",
    "        \n",
    "        if tf.less(tf.reduce_sum(plate_tear_critical_experienced_diff)+langranian, 0.1).eval():\n",
    "            print(\"done\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tests\n",
    "height = tf.constant(50e-3, dtype=tf.float64)  # m\n",
    "length = tf.constant(100e-3, dtype=tf.float64)  # m\n",
    "\n",
    "feed_dict = {load: 1}\n",
    "tf.get_default_session().run([\n",
    "        tf.assert_equal(tf.to_float(comp_horizontal[0].eval(feed_dict=feed_dict)), 1.0, [\"comp_horizontal[0] != 1.0\", comp_horizontal[0]]),\n",
    "#         tf.assert_equal(comp_horizontal[-1].eval(feed_dict=feed_dict), 6.0, [\"comp_horizontal[-0] != 6.0\", comp_horizontal[-1] ]),\n",
    "#         tf.assert_equal(tensile_horizontal[-1].eval(feed_dict=feed_dict), 5.0, [\"tensile_horizontal != 5.0\", tensile_horizontal[-1]])\n",
    "    ], feed_dict=feed_dict);\n",
    "\n",
    "# Test buckling\n",
    "feed_dict = {thickness_comp: [0.112, 6.33], width_comp: [9.32, 4.73], length_comp: [0.2231, 0.2231]}\n",
    "tf.get_default_session().run([\n",
    "        tf.assert_equal(I_min[0].eval(feed_dict=feed_dict), 1.09116081e-03, [\"I_min[0] != 1.091e-3\", I_min[0]]),\n",
    "        tf.assert_equal(I_min[1].eval(feed_dict=feed_dict), 55.82207108, [\"I_min[1] != 55.82\", I_min[1]]),\n",
    "        tf.assert_equal(buckling[0].eval(feed_dict=feed_dict), 5.66230272e8, [\"buckling[0] != 5.66e8\", buckling[0]]),\n",
    "    ], feed_dict=feed_dict);\n",
    "\n",
    "# Test pin shear\n",
    "feed_dict = {}\n",
    "tf.get_default_session().run([\n",
    "        tf.assert_equal(pin_shear.eval(feed_dict=feed_dict), 181.52492, [\"pin_shear != 181.52492\", pin_shear]),\n",
    "    ], feed_dict=feed_dict);\n",
    "\n",
    "# Test plate rupture\n",
    "feed_dict = {width_tensile: [5.22e-3], thickness_tensile: [53.2e-3]}\n",
    "tf.get_default_session().run([\n",
    "        tf.assert_equal(plate_rupture.eval(feed_dict=feed_dict), 1388.00683594, [\"plate_rupture != 1388.00683594\", plate_rupture]),\n",
    "    ], feed_dict=feed_dict);\n",
    "\n",
    "# Test bearing failure\n",
    "feed_dict = {thickness_comp: [0.112, 6.33]}\n",
    "tf.get_default_session().run([\n",
    "        tf.assert_equal(bearing_failure.eval(feed_dict=feed_dict), [41539.68359375, 2347733.5], [\"bearing_failure != [41539.68359375, 2347733.5]\", bearing_failure]),\n",
    "    ], feed_dict=feed_dict);\n",
    "\n",
    "# Test plate tear out\n",
    "feed_dict = {tearout_d_tensile: [48.22], thickness_tensile: [53.2e-3]}\n",
    "tf.get_default_session().run([\n",
    "        tf.assert_equal(plate_tearout.eval(feed_dict=feed_dict), [10261216.], [\"plate_tearout != [10261216]\", plate_tearout]),\n",
    "    ], feed_dict=feed_dict);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.Variable([1., 2., 3., 4.], name=\"x\")\n",
    "\n",
    "\n",
    "tf.initialize_all_variables().run()\n",
    "tt = x.eval()\n",
    "y = x**2\n",
    "# tf.initialize_all_variables().run()\n",
    "\n",
    "\n",
    "opt = tf.train.AdamOptimizer(0.01)\n",
    "train = opt.minimize(y)\n",
    "tf.initialize_all_variables().run()\n",
    "\n",
    "for i in range(10000):\n",
    "    tf.get_default_session().run(train)\n",
    "    if i % 1000 == 0:\n",
    "        print(\"x: {0}\".format(x.eval()))\n",
    "        print(\"tt: {0}\".format(tt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.Variable(10)\n",
    "y = x + 1\n",
    "y = tf.clip_by_value(y, 0, 8)\n",
    "tf.initialize_all_variables().run()\n",
    "print(x.eval())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
